# Disciplina: LLM: PROMPTS AND APPLICATIONS**

**Carga Horária: 80 horas**

**Período Letivo: 2025-1**

## Ementa:

Fundamentals of Large Language Models (LLMs): Transformer architecture,
training data, output generation, and LLM services. Safety and ethics in
AI: responsible AI usage, data privacy, and ethical implications. Prompt
engineering: core concepts, context windows, model randomness, knowledge
base integration, and prompt patterns. Advanced prompt techniques:
persona, self-critique, audience tailoring, and chain-of-thought
reasoning. Additional AI tools: Mixture of Experts, audio-text models,
text-image models, and agent-building tools like LangChain.
Retrieval-Augmented Generation (RAG): document management, embeddings,
and integration with CSV and web data. Evaluation and iteration: using
LangSmith for dataset preparation and model fine-tuning. Project-based
learning: technical and non-technical group projects for agent design
and implementation.

## Objetivo:

By the end of the course, students will be able to: 1. Understand and
explain the core principles of Large Language Models (LLMs), including
their training process and how output are generated; 2. Identify and
apply ethical considerations and responsible practices when engaging
with AI solutions, more specifically regarding data privacy , bias
mitigation and copyright issues; 3. Apply prompt engineering techniques
to improve model output quality and efficiency; 4. Integrate LLMs with
additional tools and modalities; 5. Design and implement AI solutions
using agent-building tools and Retrieval-Augmented Generation (RAG).

## Conteúdo programático:

Syllabus

1.  Introduction to Large Language Models (LLMs)


a.  What is an LLM: Overview of Large Language Models, their purpose,
    and significance.

b.  Transformer Architecture: Understanding the core architecture
    underlying LLMs, focusing on attention mechanisms.

c.  Training Data: How LLMs learn from data - what data is used to train
    a LLM.

d.  Output Generation (Word-by-Word): Explanation of token-by-token
    generation, controlling outputs with temperature, and
    probability-based sampling.

e.  Available LLM Services: ChatGPT; Gemini; LLaMA; Open-source models.


2.  Safety and Ethics in AI

a.  Responsible AI Usage: Understanding the importance of using AI
    responsibly, including transparency, fairness, and inclusivity.

b.  Data Privacy: Importance of safeguarding user data and
    respecting privacy regulations when developing and deploying AI
    solutions.

c.  Ethical Implications: Discussion on potential misuse of AI,
    including misinformation, deepfakes, and plagiarism, with strategies
    to promote ethical and unbiased usage.

3.  Prompt Engineering

a.  Prompt Fundamentals: Essential concepts and intuition behind
    creating effective prompts.

b.  Context Windows: How context length affects output, including
    handling truncation and memory limitations.

c.  Model Randomness: Exploring temperature, top-k, and top-p parameters
    to adjust output randomness.

d.  Knowledge Base Integration: Leveraging external data and
    retrieval-augmented generation (RAG).

e.  Foundation Prompts: Understanding core prompts and their importance.

4.  Prompt Patterns & Techniques

a.  Core Patterns:

b.  Persona Pattern: Instructing LLMs to adopt roles (e.g., specialist,
    character) ○ Critic Loop: Enabling self-critique and refinement of
    outputs

c.  Question Refinement Pattern: Improving prompt clarity and
    effectiveness through LLM suggestions

d.  Audience Persona Pattern: Tailoring prompts to a specific audience

e.  Flipped Interaction Pattern: Engaging the model to ask questions for
    deeper insights ○ Contextual Expansion Pattern: Enhance the model's
    understanding by supplying additional, relevant information to
    refine responses

f.  Gameplay Pattern: Structuring interactions in a playful or gamified
    manner

g.  Template Pattern: Reusable templates for consistent outputs

h.  Fact Check List Pattern: Extracting factual bullet points from
    longer texts

i.  Chain of Thought (CoT): Leveraging multi-step reasoning for complex
    tasks

j.  Recipe Pattern: Step-by-step instructions for predictable,
    structured responses

5.  Advanced Patterns:


a.  Meta Language Creation Pattern: Designing unique terminologies or
    symbols within prompts

b.  Alternative Approaches Pattern: Exploring diverse perspectives in
    responses

c.  Ask for Input Pattern: Directly requesting user input to refine
    responses

d.  Tail Generation Pattern: Creating concluding statements or summaries


6.  Additional AI Tools and Modalities


a.  Mixture of Experts (MoE): Overview of MoE architectures, benefits,
    and multimodal applications.

b.  Audio-Text Models: Converting audio to text, and vice versa, e.g.,
    Whisper, TTS tools.

c.  Text-Image Models: Models like DALL-E and Midjourney for generating
    images from text and vice versa.

d.  Code & Run: Tools for generating and executing code, e.g., GitHub
    Copilot.


7.  Agent-Building Tools (LangChain)


a.  API Calls: Integrating external APIs for data retrieval.

b.  Prompt Templates: Creating reusable prompt structures.

c.  Memory: Storing session-specific information across interactions.

d.  Chains: Building workflows by chaining model outputs with subsequent
    prompts.

e.  Tool Calling & Custom Tools: Accessing APIs or custom-built tools.

f.  RAG (Retrieval-Augmented Generation): Combining model responses with
    external data sources.


8.  Retrieval-Augmented Generation (RAG)


a.  Document Management:

b.  Document Loading & Splitting: Efficiently handling and chunking
    documents.

c.  Embedding & Vector Stores: Storing information through vector
    embeddings.

d.  iii\. Document Retrieval: Methods for vector store retrieval. b. RAG
    Functions i. CSV and Web inte

### Bibliografia Básica

**BB1:** Wei, Jason, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian
Ichter, Fei Xia, Ed Chi, Quoc Le, and Denny Zhou. 2022.
"Chain-of-Thought Prompting Elicits Reasoning in Large Language Models."
arXiv \[Cs.CL\]. arXiv. <http://arxiv.org/abs/2201.11903>.\
**BB2:** Yao, Shunyu, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran,
Karthik Narasimhan, and Yuan Cao. 2022. "ReAct: Synergizing Reasoning
and Acting in Language Models." arXiv \[Cs.CL\]. arXiv.
<http://arxiv.org/abs/2210.03629>.\
**BB3:** White, Jules, Quchen Fu, Sam Hays, Michael Sandborn, Carlos
Olea, Henry Gilbert, Ashraf Elnashar, Jesse Spencer-Smith, and Douglas
C. Schmidt. 2023. "A Prompt Pattern Catalog to Enhance Prompt
Engineering with ChatGPT." arXiv \[Cs.SE\]. arXiv.
<http://arxiv.org/abs/2302.11382>.

### Bibliografia Complementar

**BC1:** "Vanderbilt University Prompt Patterns." 2023. Vanderbilt
University. October 21, 2023.
<https://www.vanderbilt.edu/generative-ai/prompt-patterns/>.\
**BC2:** "LangChain Tutorials." n.d. Accessed October 22, 2024.
<https://python.langchain.com/docs/tutorials/>.

